{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "704525b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp, betaln, gammaln\n",
    "from scipy.stats import norm\n",
    "\n",
    "def pt_d_sample_test(X, Y, c=1, max_depth=-1, qdist=norm.ppf, aj=lambda depth: depth**2, log_BF=False):\n",
    "    old_expressions = np.get_printoptions()['threshold']\n",
    "    np.set_printoptions(threshold=max(max_depth, old_expressions))\n",
    "\n",
    "    if max_depth < 0:\n",
    "        max_depth = max(1, int(np.floor(np.log2(len(X)) / 2)))\n",
    "\n",
    "    binary, continuous = (X, Y) if is_discrete(X) else (Y, X)\n",
    "    data = np.column_stack([scale(continuous), binary])\n",
    "    X = data[:, 0]\n",
    "\n",
    "    p_H0 = pt_marginal_likelihood(X, low=0, up=1, c=c, depth=1, max_depth=max_depth, qdist=qdist, aj=aj)\n",
    "\n",
    "    discrete_values = binary if len(np.unique(binary)) == 2 else np.unique(binary)\n",
    "\n",
    "    p_H1 = max([pt_marginal_likelihood(data[data[:, 1] == i, 0], low=0, up=1, c=c, depth=1, max_depth=max_depth, qdist=qdist, aj=aj) +\n",
    "                pt_marginal_likelihood(data[data[:, 1] != i, 0], low=0, up=1, c=c, depth=1, max_depth=max_depth, qdist=qdist, aj=aj)\n",
    "                for i in discrete_values])\n",
    "\n",
    "    n_hypotheses = len(discrete_values)\n",
    "    bf = p_H0 - p_H1 + np.log(n_hypotheses)   #correction\n",
    "\n",
    "    np.set_printoptions(threshold=old_expressions)\n",
    "\n",
    "    if log_BF:\n",
    "        return {'bf': bf, 'p_H0': None, 'p_H1': None}\n",
    "\n",
    "    bf = np.exp(bf)\n",
    "    return {'bf': bf, 'p_H0': 1 - 1 / (1 + bf), 'p_H1': 1 / (1 + bf)}\n",
    "\n",
    "def pt_marginal_likelihood(data, low, up, c, depth, max_depth, qdist, aj):\n",
    "    if depth == max_depth:\n",
    "        return 0\n",
    "\n",
    "    if isinstance(low, (int, float)):     #if low is an integer\n",
    "        n_j = [\n",
    "            np.sum((qdist(low) < data) & (data <= qdist((low + up) / 2))),\n",
    "            np.sum((qdist((low + up) / 2) < data) & (data <= qdist(up)))\n",
    "        ]           # counts the number of data in each interval (2 vector).\n",
    "    else:\n",
    "        n_j = [\n",
    "            np.sum((qdist(low[0]) < data[:, 0]) & (data[:, 0] <= qdist((low[0] + up[0]) / 2)) &\n",
    "                   (qdist(low[1]) < data[:, 1]) & (data[:, 1] <= qdist((low[1] + up[1]) / 2))),\n",
    "            np.sum((qdist((low[0] + up[0]) / 2) < data[:, 0]) & (data[:, 0] <= qdist(up[0])) &\n",
    "                   (qdist(low[1]) < data[:, 1]) & (data[:, 1] <= qdist((low[1] + up[1]) / 2))),\n",
    "            np.sum((qdist(low[0]) < data[:, 0]) & (data[:, 0] <= qdist((low[0] + up[0]) / 2)) &\n",
    "                   (qdist((low[1] + up[1]) / 2) < data[:, 1]) & (data[:, 1] <= qdist(up[1]))),\n",
    "            np.sum((qdist((low[0] + up[0]) / 2) < data[:, 0]) & (data[:, 0] <= qdist(up[0])) &\n",
    "                   (qdist((low[1] + up[1]) / 2) < data[:, 1]) & (data[:, 1] <= qdist(up[1])))\n",
    "        ]     #4 vector\n",
    "\n",
    "    if np.sum(n_j) == 0:\n",
    "        return 0\n",
    "\n",
    "    a_j = c * aj(depth)\n",
    "\n",
    "    if len(n_j) == 2:\n",
    "        logl = betaln(n_j[0] + a_j, n_j[1] + a_j) - betaln(a_j, a_j)      #log of beta function\n",
    "    else:\n",
    "        logl = lmbeta(n_j[0] + a_j, n_j[1] + a_j, n_j[2] + a_j, n_j[3] + a_j) - lmbeta(a_j, a_j, a_j, a_j)\n",
    "\n",
    "    if isinstance(low, (int, float)):\n",
    "        likelihoods = [\n",
    "            pt_marginal_likelihood(data, low, (low + up) / 2, c, depth + 1, max_depth, qdist, aj),\n",
    "            pt_marginal_likelihood(data, (low + up) / 2, up, c, depth + 1, max_depth, qdist, aj)\n",
    "        ]    #likelihood of subpartitions\n",
    "    else:\n",
    "        likelihoods = [\n",
    "            pt_marginal_likelihood(data, low, (low + up) / 2, c, depth + 1, max_depth, qdist, aj),\n",
    "            pt_marginal_likelihood(data, (low + up) / 2, up, c, depth + 1, max_depth, qdist, aj),\n",
    "            pt_marginal_likelihood(data, [low[0], (low[1] + up[1]) / 2], [(low[0] + up[0]) / 2, up[1]], \n",
    "                                   c, depth + 1, max_depth, qdist, aj),\n",
    "            pt_marginal_likelihood(data, [(low[0] + up[0]) / 2, low[1]], [up[0], (low[1] + up[1]) / 2],\n",
    "                                   c, depth + 1, max_depth, qdist, aj)\n",
    "        ]    \n",
    "\n",
    "    return logl + np.sum(likelihoods)\n",
    "\n",
    "def lmbeta(*args):\n",
    "    return np.sum(gammaln(args)) - gammaln(np.sum(args))\n",
    "\n",
    "def is_discrete(X):\n",
    "    return np.all(np.isin(X, np.arange(11)))    #evaluates to TRUE only if every element of X lies within the specified range of 0 to 10.\n",
    "\n",
    "def scale(data):\n",
    "    return (data - np.mean(data)) / np.std(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "674fbc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bf': -0.061197476333745726, 'p_H0': None, 'p_H1': None}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "samplesize = 1000\n",
    "\n",
    "mean1 = 8\n",
    "sd1 = 10\n",
    "\n",
    "mean2 = 16\n",
    "sd2 = 12\n",
    "\n",
    "data1 = np.random.normal(loc=mean1, scale=sd1, size=samplesize)\n",
    "data2 = np.random.normal(loc=mean2, scale=sd2, size=samplesize)\n",
    "\n",
    "'''\n",
    "data1 = [20.62954285, 4.73766639, 21.29799263, 20.72429321, 12.14641434, -7.39950042, -1.28567035, 5.05279553, 7.94232827, 32.04653389,\n",
    "    15.63593461, 0.00990751, -3.47657009, 5.10538426, 5.00784882, 3.88489167, 10.52223448, -0.91921127, 12.35683299, -4.37538422,\n",
    "    5.75732115, 11.77395646, 9.33336361, 16.04189510, 7.42893226, 13.03607972, 18.85769362, 1.09046160, -4.84599354, 8.46726172,\n",
    "    5.64293444, 2.57111745, 3.66689683, 1.50528353, 15.26750747, 19.51911754, 17.92160365, 3.70486891, 20.38304101, 5.20653718,\n",
    "    25.57903090, 13.60746091, 3.47216027, -0.32043296, -3.66570547, -2.65590580, -7.63782051, 19.56536997, 16.32047129, 5.72671309\n",
    "]\n",
    "\n",
    "data2 = [\n",
    "    19.1936483, 11.4795674, 45.2963755, 6.4559306, 15.3414703, 19.0016959, 23.4189195, 13.9285180, -10.6868033, 0.8366274,\n",
    "    20.3047468, 15.8674543, 4.7122100, 14.6100961, 6.2203755, 18.9071618, -1.1011807, 20.3912935, 18.9809518, 16.7834582,\n",
    "    16.2298767, 19.0880605, 8.2118791, 14.5699749, 23.9696284, 29.2116292, 17.7252578, 14.5869568, 5.0551796, -1.2510349,\n",
    "    6.4349257, 31.0489973, 25.2657062, 13.3658125, 10.9022766, 10.9722388, 27.9638423, 12.6906637, 31.0722258, 23.7600927,\n",
    "    31.5917476, 5.5208547, 16.1004515, 5.4295393, 23.1551082, 17.4366117, 12.6139135, 33.4718608, 18.7482351, 27.9585271\n",
    "]\n",
    "\n",
    "'''\n",
    "\n",
    "pt_d_sample_test(data1, data2, log_BF=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71ade504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7827d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
